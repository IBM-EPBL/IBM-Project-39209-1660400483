{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./225, shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('Dataset/training_set',target_size=(64,64), batch_size=300,class_mode='categorical', color_mode =\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = train_datagen.flow_from_directory('Dataset/test_set',target_size=(64,64), batch_size=300,class_mode='categorical', color_mode =\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3), input_shape=(64,64,1), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512,activation='relu'))\n",
    "model.add(Dense(units=9,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BALAJI POWER MART\\AppData\\Local\\Temp\\ipykernel_9000\\1328381784.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train, steps_per_epoch=24, epochs=10,validation_data=x_test,validation_steps=40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.7087WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
      "24/24 [==============================] - 198s 8s/step - loss: 1.0028 - accuracy: 0.7087 - val_loss: 0.4846 - val_accuracy: 0.8724\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 79s 3s/step - loss: 0.2256 - accuracy: 0.9370\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 113s 5s/step - loss: 0.1109 - accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 75s 3s/step - loss: 0.0653 - accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 68s 3s/step - loss: 0.0492 - accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.0307 - accuracy: 0.9935\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.0309 - accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 60s 2s/step - loss: 0.0206 - accuracy: 0.9949\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.0171 - accuracy: 0.9960\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 55s 2s/step - loss: 0.0124 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c7650db20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, steps_per_epoch=24, epochs=10,validation_data=x_test,validation_steps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modell.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./Dataset/test_set/B/1.pngim\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1594, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1584, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1577, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1545, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"resnet50\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Development\\ibm1.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Development/ibm1.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img_preprocessed \u001b[39m=\u001b[39m preprocess_input(img_batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Development/ibm1.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mresnet50\u001b[39m.\u001b[39mResNet50()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Development/ibm1.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(img_preprocessed)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Development/ibm1.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(decode_predictions(prediction, top\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1594, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1584, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1577, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1545, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\BALAJI POWER MART\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"resnet50\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from cv2 import resize\n",
    "img = image.load_img(img_path, target_size=(64,64,1))\n",
    "img_array = image.img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "model = tf.keras.applications.resnet50.ResNet50()\n",
    "prediction = model.predict(img_preprocessed)\n",
    "print(decode_predictions(prediction, top=3)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c952e886c51800284c31907fb9fb0752a33b8f0839ac053c2b356e22a3288a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
